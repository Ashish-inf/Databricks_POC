{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f314ba6-3dd8-4b28-ab9e-3c8763b3e858",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dynamically discovers all entity folders.\n",
    "Reads streaming CSV data from each folder.\n",
    "Enriches the data with metadata.\n",
    "Creates a bronze-level DLT table for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c37e0b2e-256e-47b0-ab0a-8bf55ea50b04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import (\n",
    "#     lit, current_timestamp, regexp_extract, col, current_user, from_utc_timestamp, udf\n",
    "# )\n",
    "# from pyspark.sql.types import StringType\n",
    "# from cryptography.fernet import Fernet\n",
    "# import dlt  \n",
    "# entities = [f.name.replace(\"/\", \"\") for f in dbutils.fs.ls(\"abfss://trainingexternal@bayadapoc.dfs.core.windows.net/learners/ashish/landing/AdventureWorks_Ashish/\")]\n",
    "\n",
    "\n",
    "# #Encryption Setup\n",
    "\n",
    "# fernet_encryption_key = \"ZTZBmnJX2RHnOLJYonUFL9_r6iIUxWMUP8JqrBRZUwE=\"  # Replace with secure storage (e.g., Key Vault)\n",
    "# fernet = Fernet(fernet_encryption_key.encode())\n",
    "\n",
    "# def pii_encryption(field):\n",
    "#     if field is None:\n",
    "#         return None\n",
    "#     try:\n",
    "#         return fernet.encrypt(field.encode()).decode()\n",
    "#     except Exception:\n",
    "#         return field  # fallback if not string\n",
    "\n",
    "# encryption_function = udf(pii_encryption, StringType())\n",
    "\n",
    "# #Define PII dictionary\n",
    "\n",
    "# pii_dict = {\n",
    "#     \"EmailAddress\": [\"EmailAddress\"],\n",
    "#     \"Address\": [\"AddressLine1\", \"AddressLine2\", \"City\", \"PostalCode\"],\n",
    "#     \"Customer\": [\"AccountNumber\"],\n",
    "#     \"Person\": [\"FirstName\", \"MiddleName\", \"LastName\"],\n",
    "#     \"SalesOrderHeader\": [\"AccountNumber\"]\n",
    "# }\n",
    "\n",
    "# def create_bronze_table(entity_name):\n",
    "#     df = (\n",
    "#         spark.readStream.format(\"cloudFiles\")\n",
    "#         .option(\"cloudFiles.format\", \"csv\")\n",
    "#         .option(\"header\", \"true\")\n",
    "#         .option(\"inferSchema\", \"true\")\n",
    "#         .option(\"cloudFile.schemaEvolutionMode\", \"rescue\") \n",
    "#         .option(\"recursiveFileLookup\", \"true\")\n",
    "#         .load(f\"abfss://trainingexternal@bayadapoc.dfs.core.windows.net/learners/ashish/landing/AdventureWorks_Ashish/{entity_name}/*\")\n",
    "#         .withColumn(\"Entity\", lit(entity_name))\n",
    "#         .withColumn(\"File_Name\", regexp_extract(col(\"_metadata.file_path\"), r'landing/AdventureWorks_Ashish/'+entity_name+r'/\\d{4}/([^/]+)', 1))\n",
    "#         .withColumn(\"Year\", regexp_extract(col(\"_metadata.file_path\"), r'landing/AdventureWorks_Ashish/'+entity_name+r'/(\\d{4})', 1))\n",
    "#         .withColumn(\"Inserted_by\", current_user())\n",
    "#         .withColumn('Ingested_time', from_utc_timestamp(current_timestamp(), \"Asia/Kolkata\"))\n",
    "#     )\n",
    "\n",
    "#     if entity_name == \"Customer\":\n",
    "#         df = df.withColumn(\"AccountNumber\", encryption_function(col(\"AccountNumber\")))\n",
    "#     elif entity_name == \"Address\":\n",
    "#         df = df.withColumn(\"PostalCode\", encryption_function(col(\"PostalCode\")))\n",
    "#     elif entity_name == \"EmailAddress\":\n",
    "#         df = df.withColumn(\"EmailAddress\", encryption_function(col(\"EmailAddress\")))\n",
    "#     elif entity_name == \"Person\":\n",
    "#         df = df.withColumn(\"PersonType\", encryption_function(col(\"PersonType\")))\n",
    "\n",
    "#     return df\n",
    "\n",
    "# for entity in entities:\n",
    "   \n",
    "#     @dlt.table(\n",
    "#         name = f\"training.ashish.{entity}_bronze\",\n",
    "#         comment = f\"Bronze table for entities\"\n",
    "#     )\n",
    "#     def bronze_table(entity_name = entity):\n",
    "#         return create_bronze_table(entity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8de4d14b-7a91-486b-98ff-86dfff1d45b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    lit, current_timestamp, regexp_extract, col, current_user, from_utc_timestamp, udf\n",
    ")\n",
    "from pyspark.sql.types import StringType\n",
    "from cryptography.fernet import Fernet\n",
    "import dlt  \n",
    "\n",
    "#Get entity names dynamically from landing folder\n",
    "entities = [f.name.replace(\"/\", \"\") for f in dbutils.fs.ls(\n",
    "    \"abfss://trainingexternal@bayadapoc.dfs.core.windows.net/learners/ashish/landing/AdventureWorks_Ashish/\"\n",
    ")]\n",
    "\n",
    "\n",
    "# Encryption Setup\n",
    "\n",
    "fernet_encryption_key = \"ZTZBmnJX2RHnOLJYonUFL9_r6iIUxWMUP8JqrBRZUwE=\"  # replace with Key Vault in prod\n",
    "fernet = Fernet(fernet_encryption_key.encode())\n",
    "\n",
    "def pii_encryption(field):\n",
    "    if field is None:\n",
    "        return None\n",
    "    try:\n",
    "        return fernet.encrypt(field.encode()).decode()\n",
    "    except Exception:\n",
    "        return field  #fallback if not string\n",
    "\n",
    "encryption_function = udf(pii_encryption, StringType())\n",
    "\n",
    "\n",
    "#PII dictionary (which columns to encrypt)\n",
    "\n",
    "pii_dict = {\n",
    "    \"EmailAddress\": [\"EmailAddress\"],\n",
    "    \"Address\": [\"AddressLine1\", \"AddressLine2\", \"City\", \"PostalCode\"],\n",
    "    \"Customer\": [\"AccountNumber\"],\n",
    "    \"Person\": [\"FirstName\", \"MiddleName\", \"LastName\", \"PersonType\"],\n",
    "    \"SalesOrderHeader\": [\"AccountNumber\"]\n",
    "}\n",
    "\n",
    "\n",
    "#Bronze Table Creation Function\n",
    "\n",
    "def create_bronze_table(entity_name):\n",
    "    df = (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"cloudFile.schemaEvolutionMode\", \"rescue\") \n",
    "        .option(\"recursiveFileLookup\", \"true\")\n",
    "        .load(f\"abfss://trainingexternal@bayadapoc.dfs.core.windows.net/learners/ashish/landing/AdventureWorks_Ashish/{entity_name}/*\")\n",
    "        .withColumn(\"Entity\", lit(entity_name))\n",
    "        .withColumn(\"File_Name\", regexp_extract(col(\"_metadata.file_path\"), \n",
    "                    r'landing/AdventureWorks_Ashish/'+entity_name+r'/\\d{4}/([^/]+)', 1))\n",
    "        .withColumn(\"Year\", regexp_extract(col(\"_metadata.file_path\"), \n",
    "                    r'landing/AdventureWorks_Ashish/'+entity_name+r'/(\\d{4})', 1))\n",
    "        .withColumn(\"Inserted_by\", current_user())\n",
    "        .withColumn('Ingested_time', from_utc_timestamp(current_timestamp(), \"Asia/Kolkata\"))\n",
    "    )\n",
    "\n",
    "    #Apply encryption if entity has PII columns\n",
    "    if entity_name in pii_dict:\n",
    "        for col_name in pii_dict[entity_name]:\n",
    "            if col_name in df.columns:\n",
    "                df = df.withColumn(col_name, encryption_function(col(col_name)))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#Generate Bronze Tables dynamically\n",
    "\n",
    "for entity in entities:\n",
    "    @dlt.table(\n",
    "        name=f\"{entity}_bronze\",   #  underscore in name (avoid dots)\n",
    "        comment=f\"Bronze table for {entity} entity\",\n",
    "        table_properties={\n",
    "            \"pipelines.trigger.mode\": \"continuous\"  #  auto trigger when files land\n",
    "        }\n",
    "    )\n",
    "    def bronze_table(entity_name=entity):\n",
    "        return create_bronze_table(entity_name)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AUTOLOADER_Notebook 2025-08-21 16:54:45",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
